{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "542659e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0053c375",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_import_path = \"/nfs/turbo/hrg/somar/LLM_bib/raw_data\"\n",
    "data_export_path = \"/nfs/turbo/hrg/somar/LLM_bib/result_data\"\n",
    "result_path = \"/nfs/turbo/hrg/somar/LLM_bib/result_file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0a12d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FN Clarivate Analytics Web of Science\n",
      "0                                VR 1.0\n",
      "1                                  PT J\n",
      "2                              AU He, T\n",
      "3                                 Fu, W\n",
      "4                                Xu, JQ\n"
     ]
    }
   ],
   "source": [
    "# # read the file into a pandas DataFrame\n",
    "# wos_df = pd.read_csv(data_import_path+\"/download_chatgpt_1001_1500.txt\", delimiter='\\t', header=0, index_col=False)\n",
    "\n",
    "# # print the first 5 rows of the DataFrame\n",
    "# print(wos_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55959840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "savedrecs (2).xls\n",
      "savedrecs (3).xls\n",
      "savedrecs (4).xls\n",
      "savedrecs (5).xls\n",
      "savedrecs (6).xls\n",
      "savedrecs (7).xls\n"
     ]
    }
   ],
   "source": [
    "wos_df = pd.DataFrame()\n",
    "for file_name in sorted(os.listdir(data_import_path+\"/excel_version\")):\n",
    "    print(file_name)\n",
    "    if file_name.endswith(\".xls\"):\n",
    "        wos_df = wos_df.append(pd.read_excel(data_import_path+\"/excel_version/\"+file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6648de5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5752 entries, 0 to 751\n",
      "Data columns (total 72 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Publication Type            5752 non-null   object \n",
      " 1   Authors                     5752 non-null   object \n",
      " 2   Book Authors                10 non-null     object \n",
      " 3   Book Editors                1020 non-null   object \n",
      " 4   Book Group Authors          2209 non-null   object \n",
      " 5   Author Full Names           5752 non-null   object \n",
      " 6   Book Author Full Names      10 non-null     object \n",
      " 7   Group Authors               3 non-null      object \n",
      " 8   Article Title               5752 non-null   object \n",
      " 9   Source Title                5752 non-null   object \n",
      " 10  Book Series Title           1412 non-null   object \n",
      " 11  Book Series Subtitle        0 non-null      float64\n",
      " 12  Language                    0 non-null      float64\n",
      " 13  Document Type               5752 non-null   object \n",
      " 14  Conference Title            3206 non-null   object \n",
      " 15  Conference Date             3206 non-null   object \n",
      " 16  Conference Location         3206 non-null   object \n",
      " 17  Conference Sponsor          0 non-null      float64\n",
      " 18  Conference Host             292 non-null    object \n",
      " 19  Author Keywords             0 non-null      float64\n",
      " 20  Keywords Plus               0 non-null      float64\n",
      " 21  Abstract                    5702 non-null   object \n",
      " 22  Addresses                   5717 non-null   object \n",
      " 23  Affiliations                5399 non-null   object \n",
      " 24  Reprint Addresses           5712 non-null   object \n",
      " 25  Email Addresses             5430 non-null   object \n",
      " 26  Researcher Ids              1438 non-null   object \n",
      " 27  ORCIDs                      2470 non-null   object \n",
      " 28  Funding Orgs                3376 non-null   object \n",
      " 29  Funding Name Preferred      3364 non-null   object \n",
      " 30  Funding Text                3375 non-null   object \n",
      " 31  Cited References            5725 non-null   object \n",
      " 32  Cited Reference Count       5752 non-null   int64  \n",
      " 33  Times Cited, WoS Core       5752 non-null   int64  \n",
      " 34  Times Cited, All Databases  5752 non-null   int64  \n",
      " 35  180 Day Usage Count         0 non-null      float64\n",
      " 36  Since 2013 Usage Count      0 non-null      float64\n",
      " 37  Publisher                   0 non-null      float64\n",
      " 38  Publisher City              0 non-null      float64\n",
      " 39  Publisher Address           0 non-null      float64\n",
      " 40  ISSN                        0 non-null      float64\n",
      " 41  eISSN                       0 non-null      float64\n",
      " 42  ISBN                        0 non-null      float64\n",
      " 43  Journal Abbreviation        0 non-null      float64\n",
      " 44  Journal ISO Abbreviation    0 non-null      float64\n",
      " 45  Publication Date            1946 non-null   object \n",
      " 46  Publication Year            5575 non-null   float64\n",
      " 47  Volume                      3018 non-null   object \n",
      " 48  Issue                       1499 non-null   object \n",
      " 49  Part Number                 11 non-null     object \n",
      " 50  Supplement                  30 non-null     float64\n",
      " 51  Special Issue               127 non-null    object \n",
      " 52  Meeting Abstract            4 non-null      object \n",
      " 53  Start Page                  4100 non-null   object \n",
      " 54  End Page                    4100 non-null   object \n",
      " 55  Article Number              1242 non-null   object \n",
      " 56  DOI                         4184 non-null   object \n",
      " 57  DOI Link                    4184 non-null   float64\n",
      " 58  Book DOI                    7 non-null      object \n",
      " 59  Early Access Date           806 non-null    object \n",
      " 60  Number of Pages             0 non-null      float64\n",
      " 61  WoS Categories              0 non-null      float64\n",
      " 62  Web of Science Index        0 non-null      float64\n",
      " 63  Research Areas              0 non-null      float64\n",
      " 64  IDS Number                  0 non-null      float64\n",
      " 65  Pubmed Id                   0 non-null      float64\n",
      " 66  Open Access Designations    2133 non-null   object \n",
      " 67  Highly Cited Status         15 non-null     object \n",
      " 68  Hot Paper Status            15 non-null     object \n",
      " 69  Date of Export              5752 non-null   object \n",
      " 70  UT (Unique WOS ID)          5752 non-null   object \n",
      " 71  Web of Science Record       5752 non-null   int64  \n",
      "dtypes: float64(24), int64(4), object(44)\n",
      "memory usage: 3.2+ MB\n"
     ]
    }
   ],
   "source": [
    "wos_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cfdf4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wos_df = wos_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2285d9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "wos_abstract_df = wos_df[['Article Title','DOI','Abstract']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe1e8209",
   "metadata": {},
   "outputs": [],
   "source": [
    "wos_abstract_df[\"Article_number\"] = list(range(5752))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8300ac63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use title and abstract, as well focus on sentence-line context aware info, not keywords.\n",
    "wos_abstract_df[\"Title_abstract\"] = wos_abstract_df[\"Article Title\"]+\". \"+wos_abstract_df[\"Abstract\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59a31a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add dates\n",
    "all_years = []\n",
    "for i in range(len(wos_df)):\n",
    "    if not np.isnan(wos_df[\"Publication Year\"][i]):\n",
    "        all_years.append(int(wos_df[\"Publication Year\"][i]))\n",
    "    elif type(wos_df[\"Early Access Date\"][i])==str:\n",
    "        all_years.append(int(wos_df[\"Early Access Date\"][i][-4:]))\n",
    "    else:\n",
    "        all_years.append(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a870f20a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_years.count(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4edb7d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "wos_abstract_df[\"Year\"] = all_years"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f390956",
   "metadata": {},
   "source": [
    "### Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0131856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from umap import UMAP\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8e05213",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [str(item) for item in list(wos_abstract_df.Title_abstract)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "577f2ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "# hdbscan_model = HDBSCAN(min_cluster_size=10,\n",
    "#                         min_samples=5,\n",
    "#                         metric='euclidean',\n",
    "#                         cluster_selection_method='eom',\n",
    "#                         prediction_data=True) # random_state=42\n",
    "cluster_model = KMeans(n_clusters=200)\n",
    "topic_model = BERTopic(hdbscan_model=cluster_model, #hdbscan_model,\n",
    "                       vectorizer_model=vectorizer_model,\n",
    "                       top_n_words=10) # nr_topics=100,\n",
    "topics, probs = topic_model.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51c7664e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lizhouf/.local/lib/python3.9/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "topic_model.save(result_path+\"/LLM_wos_abstract_200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59159644",
   "metadata": {},
   "outputs": [],
   "source": [
    "wos_abstract_df[\"topics\"] = topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d80acec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article Title</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Article_number</th>\n",
       "      <th>Title_abstract</th>\n",
       "      <th>Year</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jigsaw: Large Language Models meet Program Syn...</td>\n",
       "      <td>10.1145/3510003.3510203</td>\n",
       "      <td>Large pre-trained language models such as GPT-...</td>\n",
       "      <td>0</td>\n",
       "      <td>Jigsaw: Large Language Models meet Program Syn...</td>\n",
       "      <td>2022</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Structured Pruning of Large Language Models</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Large language models have recently achieved s...</td>\n",
       "      <td>1</td>\n",
       "      <td>Structured Pruning of Large Language Models. L...</td>\n",
       "      <td>2020</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Playing Games with Ais: The Limits of GPT-3 an...</td>\n",
       "      <td>10.1007/s11023-022-09602-0</td>\n",
       "      <td>This article contributes to the debate around ...</td>\n",
       "      <td>2</td>\n",
       "      <td>Playing Games with Ais: The Limits of GPT-3 an...</td>\n",
       "      <td>2022</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Extracting Training Data from Large Language M...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>It has become common to publish large (billion...</td>\n",
       "      <td>3</td>\n",
       "      <td>Extracting Training Data from Large Language M...</td>\n",
       "      <td>2021</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Exploring Large Language Models in a Limited R...</td>\n",
       "      <td>10.1109/Confluence51648.2021.9377081</td>\n",
       "      <td>Generative Pre-trained Transformers (GPT) have...</td>\n",
       "      <td>4</td>\n",
       "      <td>Exploring Large Language Models in a Limited R...</td>\n",
       "      <td>2021</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5747</th>\n",
       "      <td>Global User-Level Perception of COVID-19 Conta...</td>\n",
       "      <td>10.2196/36238</td>\n",
       "      <td>Background: Contact tracing has been globally ...</td>\n",
       "      <td>5747</td>\n",
       "      <td>Global User-Level Perception of COVID-19 Conta...</td>\n",
       "      <td>2022</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5748</th>\n",
       "      <td>Pretrained Transformer Language Models Versus ...</td>\n",
       "      <td>10.2196/34834</td>\n",
       "      <td>Background: In recent years, social media has ...</td>\n",
       "      <td>5748</td>\n",
       "      <td>Pretrained Transformer Language Models Versus ...</td>\n",
       "      <td>2022</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5749</th>\n",
       "      <td>Robust effect of justice for others: Evidence ...</td>\n",
       "      <td>10.1360/TB-2019-0694</td>\n",
       "      <td>Maintenance of control and non-randomness is t...</td>\n",
       "      <td>5749</td>\n",
       "      <td>Robust effect of justice for others: Evidence ...</td>\n",
       "      <td>2020</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5750</th>\n",
       "      <td>TOPAS/Geant4 configuration for ionization cham...</td>\n",
       "      <td>10.1088/1361-6560/aac30e</td>\n",
       "      <td>Monte Carlo (MC) calculations are a fundamenta...</td>\n",
       "      <td>5750</td>\n",
       "      <td>TOPAS/Geant4 configuration for ionization cham...</td>\n",
       "      <td>2018</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5751</th>\n",
       "      <td>CURIOUS: Efficient Neural Architecture Search ...</td>\n",
       "      <td>10.1109/TCAD.2022.3148202</td>\n",
       "      <td>Neural networks (NNs) have been successfully d...</td>\n",
       "      <td>5751</td>\n",
       "      <td>CURIOUS: Efficient Neural Architecture Search ...</td>\n",
       "      <td>2022</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5752 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Article Title  \\\n",
       "0     Jigsaw: Large Language Models meet Program Syn...   \n",
       "1           Structured Pruning of Large Language Models   \n",
       "2     Playing Games with Ais: The Limits of GPT-3 an...   \n",
       "3     Extracting Training Data from Large Language M...   \n",
       "4     Exploring Large Language Models in a Limited R...   \n",
       "...                                                 ...   \n",
       "5747  Global User-Level Perception of COVID-19 Conta...   \n",
       "5748  Pretrained Transformer Language Models Versus ...   \n",
       "5749  Robust effect of justice for others: Evidence ...   \n",
       "5750  TOPAS/Geant4 configuration for ionization cham...   \n",
       "5751  CURIOUS: Efficient Neural Architecture Search ...   \n",
       "\n",
       "                                       DOI  \\\n",
       "0                  10.1145/3510003.3510203   \n",
       "1                                      NaN   \n",
       "2               10.1007/s11023-022-09602-0   \n",
       "3                                      NaN   \n",
       "4     10.1109/Confluence51648.2021.9377081   \n",
       "...                                    ...   \n",
       "5747                         10.2196/36238   \n",
       "5748                         10.2196/34834   \n",
       "5749                  10.1360/TB-2019-0694   \n",
       "5750              10.1088/1361-6560/aac30e   \n",
       "5751             10.1109/TCAD.2022.3148202   \n",
       "\n",
       "                                               Abstract  Article_number  \\\n",
       "0     Large pre-trained language models such as GPT-...               0   \n",
       "1     Large language models have recently achieved s...               1   \n",
       "2     This article contributes to the debate around ...               2   \n",
       "3     It has become common to publish large (billion...               3   \n",
       "4     Generative Pre-trained Transformers (GPT) have...               4   \n",
       "...                                                 ...             ...   \n",
       "5747  Background: Contact tracing has been globally ...            5747   \n",
       "5748  Background: In recent years, social media has ...            5748   \n",
       "5749  Maintenance of control and non-randomness is t...            5749   \n",
       "5750  Monte Carlo (MC) calculations are a fundamenta...            5750   \n",
       "5751  Neural networks (NNs) have been successfully d...            5751   \n",
       "\n",
       "                                         Title_abstract  Year  topics  \n",
       "0     Jigsaw: Large Language Models meet Program Syn...  2022      67  \n",
       "1     Structured Pruning of Large Language Models. L...  2020      16  \n",
       "2     Playing Games with Ais: The Limits of GPT-3 an...  2022     144  \n",
       "3     Extracting Training Data from Large Language M...  2021     125  \n",
       "4     Exploring Large Language Models in a Limited R...  2021      85  \n",
       "...                                                 ...   ...     ...  \n",
       "5747  Global User-Level Perception of COVID-19 Conta...  2022      24  \n",
       "5748  Pretrained Transformer Language Models Versus ...  2022      55  \n",
       "5749  Robust effect of justice for others: Evidence ...  2020      42  \n",
       "5750  TOPAS/Geant4 configuration for ionization cham...  2018      70  \n",
       "5751  CURIOUS: Efficient Neural Architecture Search ...  2022      58  \n",
       "\n",
       "[5752 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wos_abstract_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4628e4a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>0_aspect_sentiment_aspectbased_absa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>1_ranking_retrieval_query_document</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>89</td>\n",
       "      <td>2_visual_image_vqa_captioning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>82</td>\n",
       "      <td>3_protein_proteins_molecular_dna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>4_hate_speech_offensive_hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>5</td>\n",
       "      <td>195_covid19_pandemic_relationships_spatial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>196</td>\n",
       "      <td>5</td>\n",
       "      <td>196_kerasbert_equivalence_judging_processbert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197</td>\n",
       "      <td>4</td>\n",
       "      <td>197_music_sheet_musical_instrument</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>198</td>\n",
       "      <td>4</td>\n",
       "      <td>198_coherence_utterancepair_ffcd_unilm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>4</td>\n",
       "      <td>199_ranking_hypotheses_nbest_reranking</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic  Count                                           Name\n",
       "0        0     98            0_aspect_sentiment_aspectbased_absa\n",
       "1        1     98             1_ranking_retrieval_query_document\n",
       "2        2     89                  2_visual_image_vqa_captioning\n",
       "3        3     82               3_protein_proteins_molecular_dna\n",
       "4        4     80                4_hate_speech_offensive_hateful\n",
       "..     ...    ...                                            ...\n",
       "195    195      5     195_covid19_pandemic_relationships_spatial\n",
       "196    196      5  196_kerasbert_equivalence_judging_processbert\n",
       "197    197      4             197_music_sheet_musical_instrument\n",
       "198    198      4         198_coherence_utterancepair_ffcd_unilm\n",
       "199    199      4         199_ranking_hypotheses_nbest_reranking\n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show topics info\n",
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57d92ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic_info().to_csv(data_export_path+\"/LLM_wos_abstract_topics_metadata_200.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "525ffa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show Topic Positions -> suggestions for further clustering\n",
    "#topic_model.visualize_topics()\n",
    "fig_IDM = topic_model.visualize_topics()\n",
    "fig_IDM.write_html(result_path+\"/LLM_wos_abstract_viz_IDM_200.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78f4ac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize Topic Hierarchy -> suggestions for further clustering\n",
    "fig_hierarchy = topic_model.visualize_hierarchy()\n",
    "fig_hierarchy.write_html(result_path+\"/LLM_wos_abstract_viz_hierarchy_200.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c26055ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize words\n",
    "fig_topic_word_scores = topic_model.visualize_barchart(top_n_topics=32)\n",
    "fig_topic_word_scores.write_html(result_path+\"/LLM_wos_abstract_viz_topic_word_scores_200.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ef1ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize topic similarity -- not useful in our case, maybe include to show not correlated\n",
    "fig_heatmap = topic_model.visualize_heatmap()\n",
    "fig_heatmap.write_html(result_path+\"/LLM_wos_abstract_viz_heatmap_200.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ef4e2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize documents\n",
    "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embeddings = sentence_model.encode(docs, show_progress_bar=False)\n",
    "# Run the visualization with the original embeddings\n",
    "topic_model.visualize_documents(docs, embeddings=embeddings)\n",
    "# Reduce dimensionality of embeddings, this step is optional but much faster to perform iteratively:\n",
    "reduced_embeddings = UMAP(n_neighbors=10, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embeddings)\n",
    "# save embeddings (for Tableau)\n",
    "wos_abstract_df[\"x\"] = reduced_embeddings[:, 0]\n",
    "wos_abstract_df[\"y\"] = reduced_embeddings[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9b96345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(result_path+'/LLM_wos_abstract_embeddings_200.pickle', 'wb') as pkl:\n",
    "    pickle.dump(embeddings, pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b52686d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wos_abstract_df.to_csv(data_export_path+\"/LLM_wos_abstract_w_topics_years_positions_200.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de723e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Topic over time\n",
    "topics_over_time = topic_model.topics_over_time(docs, all_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4b2e4946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# will export tableau viz after finish\n",
    "# topics_over_time_eg_viz = topic_model.visualize_topics_over_time(topics_over_time, topics=[13, 2, 8, 10, 40, 47])\n",
    "# topics_over_time_eg_viz.write_html(result_path+\"/LLM_wos_abstract_viz_topics_over_time_eg.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb8ac56",
   "metadata": {},
   "source": [
    "TODO:\n",
    "1. Remove nan docs\n",
    "2. Group the 50 topics, or choose interesting ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8d06d9",
   "metadata": {},
   "source": [
    "Explore fields\n",
    "1. get unique\n",
    "2. coref\n",
    "3. detect ROR\n",
    "4. analyze collaboration\n",
    "\n",
    "Refs:\n",
    "- https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5065891/\n",
    "- https://core.ac.uk/download/pdf/25068797.pdf\n",
    "\n",
    "Note: we don't care about co-citation, we just aggregate collaboration in single publications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3dcbae09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                          Microsoft; Stanford University\n",
       "1                                                     NaN\n",
       "2          University of Warsaw; University of Nottingham\n",
       "3       Google Incorporated; Stanford University; Univ...\n",
       "4       Indian Institute of Technology System (IIT Sys...\n",
       "                              ...                        \n",
       "5747    Qatar Foundation (QF); Hamad Bin Khalifa Unive...\n",
       "5748    University of Limerick; Taibah University; Uni...\n",
       "5749    Xiamen University; Xiamen University; Xiamen U...\n",
       "5750    University Hospital of Giessen & Marburg; Univ...\n",
       "5751                                 Princeton University\n",
       "Name: Affiliations, Length: 5752, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wos_df.Affiliations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "022e5988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[Sobieszek, Adam] Univ Warsaw, Dept Psychol, Warsaw, Poland; [Price, Tadeusz] Univ Nottingham, Dept Philosophy, Nottingham, England'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wos_df.Addresses[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3e20af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
